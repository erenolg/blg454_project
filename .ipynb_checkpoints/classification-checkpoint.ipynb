{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e80aa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\90538\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\90538\\anaconda3\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\90538\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\90538\\anaconda3\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\90538\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\90538\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\90538\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: requests in c:\\users\\90538\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\90538\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\90538\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\90538\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\90538\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\90538\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\90538\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\90538\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\90538\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08474140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc33c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import googlenet\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Select a style transfer model and style dataset\n",
    "style_model = googlenet(weights=True)  # Pretrained GoogLeNet model\n",
    "\n",
    "# Step 2: Choose a dataset\n",
    "# Assuming you have downloaded and extracted the TinyImageNet dataset\n",
    "\n",
    "# Step 3: Define a custom dataset for style transfer\n",
    "class StyleTransferDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.data = torchvision.datasets.ImageFolder('C:\\\\Users\\\\90538\\\\Desktop\\\\data\\\\tiny-imagenet-200\\\\train_try\\\\n01443537', transform=transform)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, _ = self.data[index]\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# Step 4: Define contrastive learning method\n",
    "def contrastive_loss(image1, image2, temperature=0.5):\n",
    "    # Enable requires_grad flag for the tensors\n",
    "    image1.requires_grad_()\n",
    "    image2.requires_grad_()\n",
    "\n",
    "    # Normalize the image tensors\n",
    "    image1 = F.normalize(image1, dim=1)\n",
    "    image2 = F.normalize(image2, dim=1)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity = F.cosine_similarity(image1, image2, dim=1) / temperature\n",
    "\n",
    "    # Calculate contrastive loss\n",
    "    loss = -torch.log(torch.exp(similarity).sum() / torch.exp(similarity).diag().sum())\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Step 5: Define a linear classifier on top of the trained model\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Step 6: Prepare the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "])\n",
    "\n",
    "dataset = StyleTransferDataset(transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Step 7: Train the style transfer model with contrastive learning\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "style_model.to(device)\n",
    "style_model.eval()\n",
    "\n",
    "contrastive_optimizer = optim.Adam(style_model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for images in dataloader:\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Generate positive and negative samples\n",
    "        with torch.no_grad():\n",
    "            features = style_model(images)\n",
    "        features = F.normalize(features, dim=1)\n",
    "\n",
    "        positive_samples = features\n",
    "        negative_samples = features[torch.randperm(features.size(0))]\n",
    "\n",
    "        # Calculate contrastive loss\n",
    "        contrastive_loss_value = contrastive_loss(positive_samples, negative_samples)\n",
    "\n",
    "        # Optimize the contrastive model\n",
    "        contrastive_optimizer.zero_grad()\n",
    "        contrastive_loss_value.backward()\n",
    "        contrastive_optimizer.step()\n",
    "\n",
    "# Step 8: Freeze the trained model and train a linear classifier on top\n",
    "contrastive_model = style_model\n",
    "contrastive_model.eval()\n",
    "\n",
    "linear_classifier = LinearClassifier(1024, num_classes=200)  # TinyImageNet has 200 classes\n",
    "linear_classifier.to(device)\n",
    "\n",
    "linear_classifier_optimizer = optim.Adam(linear_classifier.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for images in dataloader:\n",
    "        images = images.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = contrastive_model(images)\n",
    "        features = F.normalize(features, dim=1)\n",
    "\n",
    "        # Train the linear classifier\n",
    "        linear_classifier_optimizer.zero_grad()\n",
    "        outputs = linear_classifier(features)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        linear_classifier_optimizer.step()\n",
    "\n",
    "# Step 9: Calculate the performance of the model\n",
    "# You can use a separate validation dataset or perform cross-validation to evaluate the performance of the model.\n",
    "\n",
    "# Step 10: Compare the results with the literature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91386399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
